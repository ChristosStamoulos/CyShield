{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f72ef9941838432aadaf325f36ff15d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca2324ead1924b4da4ae7a6c6c31b378",
              "IPY_MODEL_4ff6dafe826641d7a9b3e48793e01e75",
              "IPY_MODEL_b5f835bcc5d64be1a2f957051357430c"
            ],
            "layout": "IPY_MODEL_b7a494c6133a4c559e0c36b436406aa9"
          }
        },
        "ca2324ead1924b4da4ae7a6c6c31b378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0687da42aac43f893a627eff6ff9cfc",
            "placeholder": "​",
            "style": "IPY_MODEL_a3178db6b12f4656b5dbb199b4deacbc",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4ff6dafe826641d7a9b3e48793e01e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf24104e2cab4274821619616f09140d",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5454372dae334795a92f98a51a96a741",
            "value": 4
          }
        },
        "b5f835bcc5d64be1a2f957051357430c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a26c5a9f05e4feea878ece2739cb248",
            "placeholder": "​",
            "style": "IPY_MODEL_0b0951d946a04d85acc12b281856dfa9",
            "value": " 4/4 [00:18&lt;00:00,  3.91s/it]"
          }
        },
        "b7a494c6133a4c559e0c36b436406aa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0687da42aac43f893a627eff6ff9cfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3178db6b12f4656b5dbb199b4deacbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf24104e2cab4274821619616f09140d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5454372dae334795a92f98a51a96a741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a26c5a9f05e4feea878ece2739cb248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b0951d946a04d85acc12b281856dfa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mesv0IP-ktmt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from typing import List, Dict, Tuple\n",
        "import torch\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
        "!pip install unsloth\n",
        "# Get latest Unsloth\n",
        "!pip install --upgrade --no-deps \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
      ],
      "metadata": {
        "id": "Kp2zuDlWlD_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y torch bitsandbytes triton\n",
        "# !pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 \\\n",
        "#     --index-url https://download.pytorch.org/whl/cu118\n",
        "# !pip install triton bitsandbytes\n"
      ],
      "metadata": {
        "id": "VF9E7XAGpfiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KriKriTeacher:\n",
        "\n",
        "  def __init__(self):\n",
        "    from unsloth import FastLanguageModel\n",
        "    print(\"Loading Llama-Krikri-8B-Instruct model...\")\n",
        "    self.model, self.tokenizer = FastLanguageModel.from_pretrained(model_name=\"ilsp/Llama-Krikri-8B-Instruct\",max_seq_length=8192,load_in_4bit = True)\n",
        "\n",
        "    from transformers import TextStreamer\n",
        "    from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "    self.tokenizer = get_chat_template(\n",
        "        self.tokenizer,\n",
        "        chat_template = \"llama-3.1\",\n",
        "    )\n",
        "    FastLanguageModel.for_inference(self.model)\n",
        "\n",
        "    self.prompt_template = \"\"\"\n",
        "    Αναλύεις μηνύματα και τα κατηγοριοποιείς ως BULLY ή NON_BULLY.\n",
        "\n",
        "    Ένα μήνυμα θεωρείται cyberbullying (BULLY) όταν περιλαμβάνει:\n",
        "    1) Άμεσες απειλές, επιθέσεις, προσβολές ή παρενόχληση\n",
        "    2) Απόπειρες αποκλεισμού ή κοινωνικής απομόνωσης\n",
        "    3) Πρόθεση να βλάψει ή να ταπεινώσει\n",
        "    4) Διάδοση φημών ή ψευδών πληροφοριών\n",
        "    5) Bodyshaming ή επιθέσεις με βάση την εμφάνιση\n",
        "    6) Παρενόχληση με βάση την ταυτότητα (φυλή, θρησκεία, σεξουαλικότητα κ.λπ.)\n",
        "    7) Επίμονη ανεπιθύμητη επαφή ή συμπεριφορά καταδίωξης\n",
        "    8) Ενθάρρυνση αυτοτραυματισμού ή αυτοκτονίας\n",
        "    9) Κοινοποίηση ντροπιαστικού περιεχομένου χωρίς συγκατάθεση\n",
        "    10) Χρήση ύβρεων ή υποτιμητικής γλώσσας\n",
        "\n",
        "    Εξέτασε το πλαίσιο, την πρόθεση και τη σοβαρότητα. Κάποια παιχνιδιάρικα πειράγματα μεταξύ φίλων μπορεί να μην αποτελούν διαδικτυακό εκφοβισμό.\n",
        "    Θα απαντάς Ναι αν το μήνυμα θεωρείται cyberbullying ή Οχι αν το μήνυμα ΔΕΝ θεωρείται cyberbullying.\n",
        "\n",
        "    Απάντησε ΜΟΝΟ με μία λέξη: Ναι ή Οχι\n",
        "\n",
        "    Μήνυμα: \"{text}\"\n",
        "    Απάντηση:\"\"\"\n",
        "\n",
        "  def preprocess_text(self, text: str) -> str:\n",
        "    \"\"\"Preprocess texts for consistent handling\"\"\"\n",
        "    if pd.isna(text) or text is None:\n",
        "      return \"\"\n",
        "\n",
        "    text = str(text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "\n",
        "    # Remove @USER mentions\n",
        "    text = re.sub(r'@USER\\b', '', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'@\\w+', '[MENTION]', text)\n",
        "\n",
        "    text = re.sub(r'[!]{3,}', '!!!', text)\n",
        "    text = re.sub(r'[?]{3,}', '???', text)\n",
        "    text = re.sub(r'[.]{3,}', '...', text)\n",
        "\n",
        "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    if len(text.strip()) < 3:\n",
        "      return \"\"\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "  def classify_single_message(self, text: str, temperature: float = 0.0) -> str:\n",
        "    \"\"\"Classify a single message using KriKri\"\"\"\n",
        "    text = self.preprocess_text(text)\n",
        "\n",
        "    # Format the prompt\n",
        "    formatted_prompt = self.prompt_template.format(text=text)\n",
        "\n",
        "    # Create chat format\n",
        "    messages = [{\"role\": \"system\", \"content\": \"Είσαι ειδικός στον εντοπισμό του cyberbullying στις ψηφιακές συνομιλίες. \"},\n",
        "     {\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "    input_text = self.tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "\n",
        "    # Tokenize and generate\n",
        "    inputs = self.tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = self.model.generate(\n",
        "          **inputs,\n",
        "          max_new_tokens=4,  #  Nai h Oxi\n",
        "          temperature=temperature,\n",
        "          do_sample=temperature > 0,\n",
        "          pad_token_id= self.tokenizer.eos_token_id,\n",
        "          repetition_penalty=1.1\n",
        "          )\n",
        "\n",
        "    # Decode response\n",
        "    response = self.tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "    return response.strip()\n",
        "\n",
        "\n",
        "  def normalize_greek_response(self, response: str) -> str:\n",
        "    normalized = response.strip().lower()\n",
        "    nai_variations = ['ναι', 'nai']\n",
        "    oxi_variations = ['όχι', 'οχι', 'oxι', 'oxi', 'ochi']\n",
        "    if any(var in normalized for var in nai_variations):\n",
        "      return 'BULLY'\n",
        "    elif any(var in normalized for var in oxi_variations):\n",
        "      return 'NON_BULLY'\n",
        "    else:\n",
        "          first_word = normalized.split()[0] if normalized.split() else \"\"\n",
        "          if any(first_word.startswith(var[:2]) for var in nai_variations):\n",
        "            return 'BULLY'\n",
        "          elif any(first_word.startswith(var[:2]) for var in oxi_variations):\n",
        "            return 'NON_BULLY'\n",
        "          else:\n",
        "            print(f\"Warning: Unexpected response format: '{response}'\")\n",
        "            return 'NON_BULLY'  # Conservative default\n",
        "\n",
        "\n",
        "\n",
        "  def calculate_soft_labels(self, text: str, n_samples: int = 7) -> tuple[list[float], float]:\n",
        "    \"\"\"\n",
        "    Return soft probabilities [p_bully, p_non_bully] and confidence score.\n",
        "    Uses self-consistency with multiple samples.\n",
        "    \"\"\"\n",
        "\n",
        "    predictions = []\n",
        "    raw_responses = []\n",
        "\n",
        "    for _ in range(n_samples):\n",
        "      raw_pred = self.classify_single_message(text, temperature=0.2)\n",
        "      normalized_pred = self.normalize_greek_response(raw_pred)\n",
        "      predictions.append(normalized_pred)\n",
        "      raw_responses.append(raw_pred)\n",
        "\n",
        "    pred_counts = Counter(predictions)\n",
        "\n",
        "    total = len(predictions)\n",
        "    prob_bully = pred_counts.get('BULLY', 0) / total\n",
        "    prob_non_bully = pred_counts.get('NON_BULLY', 0) / total\n",
        "\n",
        "    if (prob_bully + prob_non_bully == 0):\n",
        "      # If no valid predictions, default to non-bullying\n",
        "      prob_bully, prob_non_bully = 0.1, 0.9\n",
        "    elif prob_bully + prob_non_bully < 1.0:\n",
        "      # If they sum to something less than 1 (e.g. .4 + .5 = .9), normalize\n",
        "      total_valid = prob_bully + prob_non_bully\n",
        "      if total_valid > 0:\n",
        "        prob_bully /= total_valid\n",
        "        prob_non_bully /= total_valid\n",
        "      else:\n",
        "        prob_bully, prob_non_bully = 0.1, 0.9\n",
        "\n",
        "    majority = 'BULLY' if prob_bully > prob_non_bully else 'NON_BULLY'\n",
        "    confidence = pred_counts.get(majority, 0) / total\n",
        "\n",
        "    return [prob_bully, prob_non_bully], confidence\n",
        "\n",
        "\n",
        "  def process_dataset(self, df: pd.DataFrame,text_column: str = 'text',label_column: str = 'label',confidence_threshold: float = 0.3) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Process DataFrame of messages, returning filtered results with soft labels.\n",
        "    \"\"\"\n",
        "\n",
        "    results = []\n",
        "\n",
        "    print(f\"Processing {len(df)} messages...\")\n",
        "    print(f\"Mode: Using hand labels as ground truth\")\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "      text = row[text_column]\n",
        "      hand_label = row[label_column] if label_column in df.columns else None\n",
        "\n",
        "      processed_text = self.preprocess_text(text)\n",
        "      if not processed_text:\n",
        "        print(f\"Skipping empty text at row {idx}\")\n",
        "        continue\n",
        "\n",
        "      # Get soft labels and confidence from LLM\n",
        "      soft_probs, confidence = self.calculate_soft_labels(processed_text)\n",
        "      llm_hard_label = 1 if soft_probs[0] > soft_probs[1] else 0\n",
        "\n",
        "      if hand_label is not None:\n",
        "      # Use hand-annotated labels as ground truth\n",
        "      # But keep LLM soft probabilities for knowledge distillation\n",
        "        result = {\n",
        "            'text': processed_text,\n",
        "            'text_original': text,\n",
        "            'label_hard': int(hand_label),  # Ground truth from annotation\n",
        "            'p_teacher': soft_probs,        # Soft probs from LLM teacher\n",
        "            'confidence': confidence,       # LLM confidence\n",
        "            'llm_label': llm_hard_label,    # LLM prediction\n",
        "            'agreement': int(hand_label) == llm_hard_label\n",
        "            }\n",
        "      else:\n",
        "        result = ''\n",
        "\n",
        "      results.append(result)\n",
        "\n",
        "      if (idx + 1) % 10 == 0:\n",
        "        print(f\"Processed {idx + 1}/{len(df)} messages\")\n",
        "\n",
        "    result_df = pd.DataFrame(results)\n",
        "\n",
        "    # Filter by confidence threshold\n",
        "    print(f\"Before filtering: {len(result_df)} samples\")\n",
        "    filtered_df = result_df[result_df['confidence'] >= confidence_threshold].copy()\n",
        "    print(f\"After confidence filtering (>= {confidence_threshold}): {len(filtered_df)} samples\")\n",
        "\n",
        "    return filtered_df\n",
        "\n",
        "\n",
        "  def save_distillation_dataset(self, df: pd.DataFrame, output_path: str):\n",
        "    \"\"\"Save the processed dataset for knowledge distillation\"\"\"\n",
        "    distillation_data = []\n",
        "    for _, row in df.iterrows():\n",
        "      distillation_data.append({\n",
        "          'text': row['text'],\n",
        "          'text_original': row['text_original'],\n",
        "          'label_hard': int(row['label_hard']),\n",
        "          'p_teacher': row['p_teacher'],\n",
        "          'confidence': float(row['confidence']),\n",
        "          'llm_label': int(row['llm_label']),           # LLM prediction\n",
        "          'agreement': bool(row['agreement']),\n",
        "          })\n",
        "\n",
        "    try:\n",
        "      from google.colab import drive\n",
        "      import os\n",
        "\n",
        "      if not os.path.exists('/content/drive'):\n",
        "        print(\"Mounting Google Drive...\")\n",
        "        drive.mount('/content/drive')\n",
        "      else:\n",
        "        print(\"Google Drive already mounted\")\n",
        "\n",
        "      drive_dir = '/content/drive/MyDrive/cyshield'\n",
        "      os.makedirs(drive_dir, exist_ok=True)\n",
        "\n",
        "      json_path = f\"{drive_dir}/{output_path}\"\n",
        "      csv_path = json_path.replace('.json', '.csv')\n",
        "\n",
        "    except ImportError:\n",
        "      print(\"Saving locally\")\n",
        "      json_path = output_path\n",
        "      csv_path = output_path.replace('.json', '.csv')\n",
        "\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "      json.dump(distillation_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"Saved {len(distillation_data)} samples\")\n",
        "\n",
        "    csv_path = output_path.replace('.json', '.csv')\n",
        "    df.to_csv(csv_path, index=False, encoding='utf-8')\n",
        "    print(f\"Also saved as CSV: {csv_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "73LRAtRMiCD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_dataset(csv_path: str, text_col: str = 'text', label_col: str = 'label', confidence_threshold: float = 0.3):\n",
        "  print(f\"Loading dataset from {csv_path}\")\n",
        "  df = pd.read_csv(csv_path, encoding='utf-8')\n",
        "\n",
        "  print(f\"Dataset shape: {df.shape}\")\n",
        "  has_hand_labels = label_col in df.columns\n",
        "  if has_hand_labels:\n",
        "    hand_label_dist = df[label_col].value_counts()\n",
        "    print(f\"Hand-labeled distribution: {dict(hand_label_dist)}\")\n",
        "\n",
        "  teacher = KriKriTeacher()\n",
        "\n",
        "  processed_df = teacher.process_dataset(df, text_column=text_col, label_column=label_col,confidence_threshold=confidence_threshold)\n",
        "\n",
        "  output_path = csv_path.replace('.csv', f'_teacher_labels.json')\n",
        "  teacher.save_distillation_dataset(processed_df, output_path)\n",
        "\n",
        "  print(\"\\n=== FINAL STATISTICS ===\")\n",
        "  print(f\"Total processed samples: {len(processed_df)}\")\n",
        "  print(f\"Average LLM confidence: {processed_df['confidence'].mean():.3f}\")\n",
        "  print(f\"Final label distribution: {processed_df['label_hard'].value_counts().to_dict()}\")\n",
        "\n",
        "  if has_hand_labels and 'agreement' in processed_df.columns:\n",
        "    overall_agreement = processed_df['agreement'].mean()\n",
        "    print(f\"Overall LLM-Human Agreement: {overall_agreement:.3f}\")\n",
        "\n",
        "    disagreements = processed_df[~processed_df['agreement']]\n",
        "    if len(disagreements) > 0:\n",
        "      print(f\"Disagreements: {len(disagreements)} samples\")\n",
        "      print(\"Sample disagreements:\")\n",
        "      for idx, row in disagreements.head(3).iterrows():\n",
        "        print(f\"  Text: '{row['text'][:100]}...'\")\n",
        "        print(f\"  Human: {row['label_hard']}, LLM: {row['llm_label']}, Confidence: {row['confidence']:.2f}\")\n",
        "\n",
        "  return processed_df"
      ],
      "metadata": {
        "id": "DVmIOm-0QqFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "csv_file_path = '/content/drive/MyDrive/cyshield/combined.csv'\n",
        "\n",
        "processed_data = load_and_process_dataset(\n",
        "    csv_path=csv_file_path,\n",
        "    text_col='text',\n",
        "    label_col='label',\n",
        "    confidence_threshold=0.15\n",
        "    )\n",
        "\n",
        "print(\"Teacher labeling complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f72ef9941838432aadaf325f36ff15d4",
            "ca2324ead1924b4da4ae7a6c6c31b378",
            "4ff6dafe826641d7a9b3e48793e01e75",
            "b5f835bcc5d64be1a2f957051357430c",
            "b7a494c6133a4c559e0c36b436406aa9",
            "c0687da42aac43f893a627eff6ff9cfc",
            "a3178db6b12f4656b5dbb199b4deacbc",
            "cf24104e2cab4274821619616f09140d",
            "5454372dae334795a92f98a51a96a741",
            "5a26c5a9f05e4feea878ece2739cb248",
            "0b0951d946a04d85acc12b281856dfa9"
          ]
        },
        "id": "C0zpVts4dMv1",
        "outputId": "64673475-9c2a-42f5-b552-66d7ae199419"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loading dataset from /content/drive/MyDrive/cyshield/combined.csv\n",
            "Dataset shape: (2569, 2)\n",
            "Hand-labeled distribution: {0: np.int64(1788), 1: np.int64(781)}\n",
            "Loading Llama-Krikri-8B-Instruct model...\n",
            "==((====))==  Unsloth 2025.5.8: Fast Llama patching. Transformers: 4.52.3.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f72ef9941838432aadaf325f36ff15d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 2569 messages...\n",
            "Mode: Using hand labels as ground truth\n",
            "Processed 10/2569 messages\n",
            "Processed 20/2569 messages\n",
            "Processed 30/2569 messages\n",
            "Processed 40/2569 messages\n",
            "Processed 50/2569 messages\n",
            "Processed 60/2569 messages\n",
            "Processed 70/2569 messages\n",
            "Processed 80/2569 messages\n",
            "Processed 90/2569 messages\n",
            "Processed 100/2569 messages\n",
            "Processed 110/2569 messages\n",
            "Processed 120/2569 messages\n",
            "Processed 130/2569 messages\n",
            "Processed 140/2569 messages\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Processed 150/2569 messages\n",
            "Processed 160/2569 messages\n",
            "Processed 170/2569 messages\n",
            "Processed 180/2569 messages\n",
            "Processed 190/2569 messages\n",
            "Processed 200/2569 messages\n",
            "Processed 210/2569 messages\n",
            "Processed 220/2569 messages\n",
            "Processed 230/2569 messages\n",
            "Processed 240/2569 messages\n",
            "Processed 250/2569 messages\n",
            "Processed 260/2569 messages\n",
            "Processed 270/2569 messages\n",
            "Processed 280/2569 messages\n",
            "Processed 290/2569 messages\n",
            "Processed 300/2569 messages\n",
            "Processed 310/2569 messages\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Processed 320/2569 messages\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Processed 330/2569 messages\n",
            "Processed 340/2569 messages\n",
            "Processed 350/2569 messages\n",
            "Processed 360/2569 messages\n",
            "Processed 370/2569 messages\n",
            "Processed 380/2569 messages\n",
            "Processed 390/2569 messages\n",
            "Processed 400/2569 messages\n",
            "Processed 410/2569 messages\n",
            "Processed 420/2569 messages\n",
            "Processed 430/2569 messages\n",
            "Processed 440/2569 messages\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Processed 450/2569 messages\n",
            "Processed 460/2569 messages\n",
            "Processed 470/2569 messages\n",
            "Processed 480/2569 messages\n",
            "Processed 490/2569 messages\n",
            "Processed 500/2569 messages\n",
            "Processed 510/2569 messages\n",
            "Processed 520/2569 messages\n",
            "Processed 530/2569 messages\n",
            "Processed 540/2569 messages\n",
            "Processed 550/2569 messages\n",
            "Processed 560/2569 messages\n",
            "Processed 570/2569 messages\n",
            "Processed 580/2569 messages\n",
            "Processed 590/2569 messages\n",
            "Processed 600/2569 messages\n",
            "Processed 610/2569 messages\n",
            "Processed 620/2569 messages\n",
            "Processed 630/2569 messages\n",
            "Processed 640/2569 messages\n",
            "Processed 650/2569 messages\n",
            "Processed 660/2569 messages\n",
            "Processed 670/2569 messages\n",
            "Processed 680/2569 messages\n",
            "Processed 690/2569 messages\n",
            "Processed 700/2569 messages\n",
            "Processed 710/2569 messages\n",
            "Processed 720/2569 messages\n",
            "Processed 730/2569 messages\n",
            "Processed 740/2569 messages\n",
            "Processed 750/2569 messages\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Processed 760/2569 messages\n",
            "Processed 770/2569 messages\n",
            "Processed 780/2569 messages\n",
            "Processed 790/2569 messages\n",
            "Processed 800/2569 messages\n",
            "Processed 810/2569 messages\n",
            "Processed 820/2569 messages\n",
            "Processed 830/2569 messages\n",
            "Processed 840/2569 messages\n",
            "Processed 850/2569 messages\n",
            "Processed 860/2569 messages\n",
            "Processed 870/2569 messages\n",
            "Processed 880/2569 messages\n",
            "Processed 890/2569 messages\n",
            "Processed 900/2569 messages\n",
            "Processed 910/2569 messages\n",
            "Processed 920/2569 messages\n",
            "Processed 930/2569 messages\n",
            "Processed 940/2569 messages\n",
            "Processed 950/2569 messages\n",
            "Processed 960/2569 messages\n",
            "Processed 970/2569 messages\n",
            "Processed 980/2569 messages\n",
            "Processed 990/2569 messages\n",
            "Processed 1000/2569 messages\n",
            "Processed 1010/2569 messages\n",
            "Processed 1020/2569 messages\n",
            "Processed 1030/2569 messages\n",
            "Processed 1040/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "def'\n",
            "Processed 1050/2569 messages\n",
            "Processed 1060/2569 messages\n",
            "Processed 1070/2569 messages\n",
            "Processed 1080/2569 messages\n",
            "Processed 1090/2569 messages\n",
            "Processed 1100/2569 messages\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Processed 1110/2569 messages\n",
            "Processed 1120/2569 messages\n",
            "Processed 1130/2569 messages\n",
            "Processed 1140/2569 messages\n",
            "Processed 1150/2569 messages\n",
            "Processed 1160/2569 messages\n",
            "Processed 1170/2569 messages\n",
            "Processed 1180/2569 messages\n",
            "Processed 1190/2569 messages\n",
            "Processed 1200/2569 messages\n",
            "Processed 1210/2569 messages\n",
            "Processed 1220/2569 messages\n",
            "Processed 1230/2569 messages\n",
            "Processed 1240/2569 messages\n",
            "Processed 1250/2569 messages\n",
            "Processed 1260/2569 messages\n",
            "Processed 1270/2569 messages\n",
            "Processed 1280/2569 messages\n",
            "Processed 1290/2569 messages\n",
            "Processed 1300/2569 messages\n",
            "Processed 1310/2569 messages\n",
            "Processed 1320/2569 messages\n",
            "Processed 1330/2569 messages\n",
            "Processed 1340/2569 messages\n",
            "Processed 1350/2569 messages\n",
            "Processed 1360/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "def'\n",
            "Processed 1370/2569 messages\n",
            "Processed 1380/2569 messages\n",
            "Processed 1390/2569 messages\n",
            "Processed 1400/2569 messages\n",
            "Processed 1410/2569 messages\n",
            "Processed 1420/2569 messages\n",
            "Processed 1430/2569 messages\n",
            "Processed 1440/2569 messages\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Processed 1450/2569 messages\n",
            "Processed 1460/2569 messages\n",
            "Processed 1470/2569 messages\n",
            "Processed 1480/2569 messages\n",
            "Processed 1490/2569 messages\n",
            "Processed 1500/2569 messages\n",
            "Processed 1510/2569 messages\n",
            "Processed 1520/2569 messages\n",
            "Processed 1530/2569 messages\n",
            "Processed 1540/2569 messages\n",
            "Processed 1550/2569 messages\n",
            "Processed 1560/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 1570/2569 messages\n",
            "Processed 1580/2569 messages\n",
            "Processed 1590/2569 messages\n",
            "Processed 1600/2569 messages\n",
            "Processed 1610/2569 messages\n",
            "Processed 1620/2569 messages\n",
            "Processed 1630/2569 messages\n",
            "Processed 1640/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 1650/2569 messages\n",
            "Processed 1660/2569 messages\n",
            "Processed 1670/2569 messages\n",
            "Processed 1680/2569 messages\n",
            "Processed 1690/2569 messages\n",
            "Processed 1700/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Processed 1710/2569 messages\n",
            "Processed 1720/2569 messages\n",
            "Processed 1730/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 1740/2569 messages\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Processed 1750/2569 messages\n",
            "Processed 1760/2569 messages\n",
            "Processed 1770/2569 messages\n",
            "Processed 1780/2569 messages\n",
            "Processed 1790/2569 messages\n",
            "Processed 1800/2569 messages\n",
            "Processed 1810/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "ΟΧ'\n",
            "Processed 1820/2569 messages\n",
            "Processed 1830/2569 messages\n",
            "Processed 1840/2569 messages\n",
            "Processed 1850/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "print'\n",
            "Processed 1860/2569 messages\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 1870/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 1880/2569 messages\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 1890/2569 messages\n",
            "Processed 1900/2569 messages\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 1910/2569 messages\n",
            "Processed 1920/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "print'\n",
            "Processed 1930/2569 messages\n",
            "Processed 1940/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 1950/2569 messages\n",
            "Processed 1960/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "print'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 1970/2569 messages\n",
            "Processed 1980/2569 messages\n",
            "Processed 1990/2569 messages\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 2000/2569 messages\n",
            "Processed 2010/2569 messages\n",
            "Processed 2020/2569 messages\n",
            "Processed 2030/2569 messages\n",
            "Processed 2040/2569 messages\n",
            "Processed 2050/2569 messages\n",
            "Processed 2060/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "print'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 2070/2569 messages\n",
            "Skipping empty text at row 2070\n",
            "Processed 2080/2569 messages\n",
            "Processed 2090/2569 messages\n",
            "Processed 2100/2569 messages\n",
            "Processed 2110/2569 messages\n",
            "Processed 2120/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "print'\n",
            "Processed 2130/2569 messages\n",
            "Processed 2140/2569 messages\n",
            "Processed 2150/2569 messages\n",
            "Processed 2160/2569 messages\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Processed 2170/2569 messages\n",
            "Processed 2180/2569 messages\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Processed 2190/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 2200/2569 messages\n",
            "Processed 2210/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "print'\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Processed 2220/2569 messages\n",
            "Processed 2230/2569 messages\n",
            "Processed 2240/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "print'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "print'\n",
            "Warning: Unexpected response format: '```python\n",
            "print'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 2250/2569 messages\n",
            "Processed 2260/2569 messages\n",
            "Warning: Unexpected response format: '```output\n",
            "Ο'\n",
            "Processed 2270/2569 messages\n",
            "Processed 2280/2569 messages\n",
            "Processed 2290/2569 messages\n",
            "Processed 2300/2569 messages\n",
            "Processed 2310/2569 messages\n",
            "Processed 2320/2569 messages\n",
            "Processed 2330/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 2340/2569 messages\n",
            "Processed 2350/2569 messages\n",
            "Processed 2360/2569 messages\n",
            "Processed 2370/2569 messages\n",
            "Processed 2380/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 2390/2569 messages\n",
            "Processed 2400/2569 messages\n",
            "Processed 2410/2569 messages\n",
            "Processed 2420/2569 messages\n",
            "Processed 2430/2569 messages\n",
            "Processed 2440/2569 messages\n",
            "Processed 2450/2569 messages\n",
            "Processed 2460/2569 messages\n",
            "Processed 2470/2569 messages\n",
            "Processed 2480/2569 messages\n",
            "Processed 2490/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 2500/2569 messages\n",
            "Processed 2510/2569 messages\n",
            "Processed 2520/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 2530/2569 messages\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Warning: Unexpected response format: '```python\n",
            "#'\n",
            "Processed 2540/2569 messages\n",
            "Processed 2550/2569 messages\n",
            "Processed 2560/2569 messages\n",
            "Before filtering: 2568 samples\n",
            "After confidence filtering (>= 0.15): 2568 samples\n",
            "Google Drive already mounted\n",
            "Saved 2568 samples\n",
            "Also saved as CSV: /content/drive/MyDrive/cyshield/combined_teacher_labels.csv\n",
            "\n",
            "=== FINAL STATISTICS ===\n",
            "Total processed samples: 2568\n",
            "Average LLM confidence: 0.984\n",
            "Final label distribution: {0: 1787, 1: 781}\n",
            "Overall LLM-Human Agreement: 0.788\n",
            "Disagreements: 545 samples\n",
            "Sample disagreements:\n",
            "  Text: 'Θέλω να των δω από εδώ και εμπρός αν δεν κάνει το καλό παιδί αν τον πολεμήσουν στο 1/3 από όσο πολέμ...'\n",
            "  Human: 0, LLM: 1, Confidence: 0.71\n",
            "  Text: 'μην μας το παιζεις πονοψυχη,κρυφορατσιστρια του κερατα. μεταξυ σας αυτα να τα λετε,δημοσιως δεν πιαν...'\n",
            "  Human: 0, LLM: 1, Confidence: 1.00\n",
            "  Text: 'Ήταν της ΜΚΟ το βαν καλή μου. Τι να πούνε ότι είναι μαλακες;...'\n",
            "  Human: 1, LLM: 0, Confidence: 1.00\n",
            "Teacher labeling complete\n"
          ]
        }
      ]
    }
  ]
}