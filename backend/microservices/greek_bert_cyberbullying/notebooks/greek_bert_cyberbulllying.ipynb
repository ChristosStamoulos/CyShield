{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1JaDYngOp_L"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification,TrainingArguments, Trainer, EarlyStoppingCallback, DataCollatorWithPadding\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, auc, roc_curve, precision_recall_curve\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from typing import Dict, List, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers datasets accelerate evaluate scikit-learn matplotlib seaborn\n",
        "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "collapsed": true,
        "id": "V6zbXvPgSn7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting distillation dataset"
      ],
      "metadata": {
        "id": "_MJR6bP8SuZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CyberbullyingDataset(Dataset):\n",
        "  def __init__(self, texts: List[str], hard_labels: List[int], soft_labels: List[List[float]], tokenizer, max_length: int = 128):\n",
        "    self.texts = texts\n",
        "    self.hard_labels = hard_labels\n",
        "    self.soft_labels = soft_labels\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_length = max_length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    text = str(self.texts[idx])\n",
        "    encoding = self.tokenizer(text,truncation=True,padding='max_length',max_length=self.max_length,return_tensors='pt')\n",
        "\n",
        "    return {\n",
        "        'input_ids': encoding['input_ids'].flatten(),\n",
        "        'attention_mask': encoding['attention_mask'].flatten(),\n",
        "        'labels': torch.tensor(self.hard_labels[idx], dtype=torch.long),\n",
        "        'soft_labels': torch.tensor(self.soft_labels[idx], dtype=torch.float)\n",
        "        }"
      ],
      "metadata": {
        "id": "uJASUsxPSoxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer"
      ],
      "metadata": {
        "id": "n_g0iUVJWQmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistillationTrainer(Trainer):\n",
        "  def __init__(self, temperature: float = 2.0, alpha: float = 0.3, *args, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.temperature = temperature\n",
        "    self.alpha = alpha\n",
        "\n",
        "  def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "\n",
        "    labels = inputs.get(\"labels\")\n",
        "    soft_labels = inputs.get(\"soft_labels\")\n",
        "\n",
        "    # create a new dict withouot labels and soft_labels and pass it in the model\n",
        "    outputs = model(**{k: v for k, v in inputs.items() if k not in [\"labels\", \"soft_labels\"]})\n",
        "    logits = outputs.get(\"logits\")\n",
        "\n",
        "    ce_loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "    # Soft loss (KL divergence with teacher probabilities)\n",
        "    student_probs = F.log_softmax(logits / self.temperature, dim=-1)\n",
        "    teacher_probs = soft_labels\n",
        "\n",
        "    teacher_probs = teacher_probs / teacher_probs.sum(dim=-1, keepdim=True)\n",
        "\n",
        "    kl_loss = F.kl_div(student_probs, teacher_probs, reduction='batchmean')\n",
        "    soft_loss = kl_loss * (self.temperature ** 2)\n",
        "\n",
        "\n",
        "    total_loss = self.alpha * ce_loss + (1 - self.alpha) * soft_loss\n",
        "\n",
        "    return (total_loss, outputs) if return_outputs else total_loss\n"
      ],
      "metadata": {
        "id": "Tsq7MbSVWSPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_distillation_data(json_path: str) -> Tuple[List[str], List[int], List[List[float]]]:\n",
        "  \"\"\"Load the teacher-labeled dataset\"\"\"\n",
        "  with open(json_path, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  texts = [item['text'] for item in data]\n",
        "  hard_labels = [item['label_hard'] for item in data]\n",
        "  soft_labels = [item['p_teacher'] for item in data]\n",
        "\n",
        "  print(f\"Loaded {len(texts)} samples\")\n",
        "  print(f\"Label distribution: {pd.Series(hard_labels).value_counts().to_dict()}\")\n",
        "\n",
        "  return texts, hard_labels, soft_labels"
      ],
      "metadata": {
        "id": "Eo4ZnuEAxwCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "  \"\"\"Compute evaluation metrics\"\"\"\n",
        "  predictions, labels = eval_pred\n",
        "  predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "  # Basic metrics\n",
        "  accuracy = accuracy_score(labels, predictions)\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
        "\n",
        "  # ROC AUC (using probabilities)\n",
        "  # probs = F.softmax(torch.tensor(eval_pred.predictions), dim=-1).numpy()\n",
        "  # probs = torch.softmax(torch.tensor(predictions), dim=-1).numpy()\n",
        "  # pos_probs = probs[:, 1]\n",
        "  probs = F.softmax(torch.tensor(eval_pred.predictions), dim=-1).numpy()\n",
        "  pos_probs = probs[:, 1]\n",
        "  try:\n",
        "    # roc_auc = roc_auc_score(labels, probs[:, 1])\n",
        "    # For ROC AUC\n",
        "    fpr, tpr, _ = roc_curve(labels, pos_probs)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # For PR AUC\n",
        "    # precision_curve, recall_curve, _ = precision_recall_curve(labels, pos_probs)\n",
        "    # pr_auc = auc(recall_curve, precision_curve)\n",
        "\n",
        "  except ValueError:\n",
        "    roc_auc = 0.5\n",
        "\n",
        "  return {\n",
        "      'accuracy': accuracy,\n",
        "      'precision': precision,\n",
        "      'recall': recall,\n",
        "      'f1': f1,\n",
        "      'roc_auc': roc_auc\n",
        "      }"
      ],
      "metadata": {
        "id": "1zdBwSHhyeif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_student_model(\n",
        "    json_path: str,\n",
        "    model_name: str = \"nlpaueb/bert-base-greek-uncased-v1\",\n",
        "    output_dir: str = \"./cyberbullying_bert\",\n",
        "    max_length: int = 128,\n",
        "    batch_size: int = 16,\n",
        "    num_epochs: int = 7,\n",
        "    learning_rate: float = 2e-5,\n",
        "    temperature: float = 2.0,\n",
        "    alpha: float = 0.5,\n",
        "    test_size: float = 0.2,\n",
        "    validation_size: float = 0.1\n",
        "    ):\n",
        "\n",
        "  print(\"Starting BERT Training with Knowledge Distillation\")\n",
        "  print(f\"Model: {model_name}\")\n",
        "\n",
        "  texts, hard_labels, soft_labels = load_distillation_data(json_path)\n",
        "\n",
        "  X_temp, X_test, y_temp, y_test, soft_temp, soft_test = train_test_split(\n",
        "      texts, hard_labels, soft_labels, test_size=test_size, random_state=42, stratify=hard_labels\n",
        "      )\n",
        "\n",
        "  X_train, X_val, y_train, y_val, soft_train, soft_val = train_test_split(\n",
        "      X_temp, y_temp, soft_temp, test_size=validation_size/(1-test_size), random_state=42, stratify=y_temp\n",
        "      )\n",
        "\n",
        "  print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "  data_collator = DataCollatorWithPadding(tokenizer=tokenizer,padding=True,return_tensors=\"pt\")\n",
        "\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(\n",
        "      model_name,\n",
        "      num_labels=2,\n",
        "      problem_type=\"single_label_classification\"\n",
        "      )\n",
        "\n",
        "  train_dataset = CyberbullyingDataset(X_train, y_train, soft_train, tokenizer, max_length)\n",
        "  val_dataset = CyberbullyingDataset(X_val, y_val, soft_val, tokenizer, max_length)\n",
        "  test_dataset = CyberbullyingDataset(X_test, y_test, soft_test, tokenizer, max_length)\n",
        "\n",
        "  training_args = TrainingArguments(\n",
        "      output_dir=output_dir,\n",
        "      num_train_epochs=num_epochs,\n",
        "      per_device_train_batch_size=batch_size,\n",
        "      per_device_eval_batch_size=batch_size,\n",
        "      warmup_steps=100,\n",
        "      weight_decay=0.01,\n",
        "      logging_dir=f'{output_dir}/logs',\n",
        "      logging_strategy=\"steps\",\n",
        "      eval_strategy =\"steps\",\n",
        "      save_strategy=\"steps\",\n",
        "      load_best_model_at_end=True,\n",
        "      metric_for_best_model=\"f1\",\n",
        "      greater_is_better=True,\n",
        "      save_total_limit=3,\n",
        "      report_to=None,  # Disable wandb\n",
        "      learning_rate=learning_rate,\n",
        "      fp16=True,\n",
        "      seed=33,\n",
        "      remove_unused_columns=False\n",
        "      )\n",
        "\n",
        "  trainer = DistillationTrainer(\n",
        "        temperature=temperature,\n",
        "        alpha=alpha,\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
        "    )\n",
        "\n",
        "  print(\"Starting fine tuning...\")\n",
        "  trainer.train()\n",
        "\n",
        "  # Evaluate on test set\n",
        "  print(\"Evaluating on test set...\")\n",
        "  test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "  print(\"\\n=== FINAL TEST RESULTS ===\")\n",
        "  for key, value in test_results.items():\n",
        "    if key.startswith('eval_'):\n",
        "      metric_name = key.replace('eval_', '')\n",
        "      print(f\"{metric_name}: {value:.4f}\")\n",
        "\n",
        "  print(f\"Saving model to {output_dir}\")\n",
        "  trainer.save_model()\n",
        "  tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "  # Save training info\n",
        "  training_info = {\n",
        "      'model_name': model_name,\n",
        "      'temperature': temperature,\n",
        "      'alpha': alpha,\n",
        "      'max_length': max_length,\n",
        "      'test_results': test_results,\n",
        "      'training_args': training_args.to_dict()\n",
        "      }\n",
        "\n",
        "  try:\n",
        "      from google.colab import drive\n",
        "      import os\n",
        "\n",
        "      if not os.path.exists('/content/drive'):\n",
        "        print(\"Mounting Google Drive...\")\n",
        "        drive.mount('/content/drive')\n",
        "      else:\n",
        "        print(\"Google Drive already mounted\")\n",
        "\n",
        "      drive_dir = '/content/drive/MyDrive/cyshield'\n",
        "      os.makedirs(drive_dir, exist_ok=True)\n",
        "\n",
        "      print(f\"Saving model & tokenizer to {drive_dir}\")\n",
        "      trainer.save_model(drive_dir)\n",
        "      tokenizer.save_pretrained(drive_dir)\n",
        "\n",
        "  except ImportError:\n",
        "    print(\"Saving locally\")\n",
        "\n",
        "\n",
        "\n",
        "  with open(f\"{output_dir}/training_info.json\", 'w') as f:\n",
        "    json.dump(training_info, f, indent=2)\n",
        "\n",
        "  print(\"Training complete!\")\n",
        "  return trainer, test_results"
      ],
      "metadata": {
        "id": "2jGAsDXw2fAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ],
      "metadata": {
        "id": "IB95AO_2M0iD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "json_path = '/content/drive/MyDrive/cyshield/combined_teacher_labels.json'\n",
        "\n",
        "trainer, results = train_student_model(\n",
        "    json_path=json_path,\n",
        "    model_name=\"nlpaueb/bert-base-greek-uncased-v1\",\n",
        "    output_dir=\"./cyberbullying_bert\",\n",
        "    max_length=128,\n",
        "    batch_size=8,\n",
        "    num_epochs=9,\n",
        "    learning_rate=1e-5,\n",
        "    temperature=1.5,\n",
        "    alpha=0.9,       # Balance: 30% hard loss, 70% soft loss\n",
        "    )\n",
        "\n",
        "print(\"\\nTraining finished!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "1yQ1SbXPFzOl",
        "outputId": "ff857919-23b8-4c9f-fc89-62ca4635ee40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Starting BERT Training with Knowledge Distillation\n",
            "Model: nlpaueb/bert-base-greek-uncased-v1\n",
            "Loaded 2568 samples\n",
            "Label distribution: {0: 1787, 1: 781}\n",
            "Train: 1797, Val: 257, Test: 514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/bert-base-greek-uncased-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fine tuning...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2025' max='2025' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2025/2025 01:54, Epoch 9/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.624200</td>\n",
              "      <td>0.590833</td>\n",
              "      <td>0.852140</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>0.765432</td>\n",
              "      <td>0.921179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.497200</td>\n",
              "      <td>0.643040</td>\n",
              "      <td>0.879377</td>\n",
              "      <td>0.747368</td>\n",
              "      <td>0.910256</td>\n",
              "      <td>0.820809</td>\n",
              "      <td>0.892136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.451900</td>\n",
              "      <td>0.614788</td>\n",
              "      <td>0.879377</td>\n",
              "      <td>0.747368</td>\n",
              "      <td>0.910256</td>\n",
              "      <td>0.820809</td>\n",
              "      <td>0.901518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.420500</td>\n",
              "      <td>0.585617</td>\n",
              "      <td>0.898833</td>\n",
              "      <td>0.802326</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.841463</td>\n",
              "      <td>0.903058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [65/65 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== FINAL TEST RESULTS ===\n",
            "loss: 0.5912\n",
            "accuracy: 0.8911\n",
            "precision: 0.8247\n",
            "recall: 0.8141\n",
            "f1: 0.8194\n",
            "roc_auc: 0.8969\n",
            "runtime: 1.1015\n",
            "samples_per_second: 466.6510\n",
            "steps_per_second: 59.0120\n",
            "Saving model to ./cyberbullying_bert\n",
            "Google Drive already mounted\n",
            "Saving model & tokenizer to /content/drive/MyDrive/cyshield\n",
            "Training complete!\n",
            "\n",
            "Training finished!\n"
          ]
        }
      ]
    }
  ]
}